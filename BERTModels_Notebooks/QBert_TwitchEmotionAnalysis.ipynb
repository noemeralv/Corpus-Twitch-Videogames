{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46644810",
   "metadata": {
    "id": "46644810"
   },
   "source": [
    "#  Fine-tuning to a BERT-based model with classification layer: Emtion detection in videogames and Twitch\n",
    "\n",
    "The main idea is to use BERT models to tokenise texts to be classified by a new neural network, which will be placed at the output of the tokeniser. The idea of this is to \"specialise\" the classifier on the given task, in this case, classifying twitch comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z86ebKxdpOOV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 159920,
     "status": "ok",
     "timestamp": 1714986088411,
     "user": {
      "displayName": "juan pinto",
      "userId": "11813184739406666163"
     },
     "user_tz": -120
    },
    "id": "z86ebKxdpOOV",
    "outputId": "846ca66c-0a1a-4c34-c462-e6d66dc45a6e"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install torch torchvision\n",
    "!pip install scikit-learn\n",
    "!pip install matplotlib\n",
    "!pip install tqdm\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IdUrE_yDAwPF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5336,
     "status": "ok",
     "timestamp": 1714986257694,
     "user": {
      "displayName": "juan pinto",
      "userId": "11813184739406666163"
     },
     "user_tz": -120
    },
    "id": "IdUrE_yDAwPF",
    "outputId": "a1290c88-cc6d-468c-9ab5-9a7f092d2818"
   },
   "outputs": [],
   "source": [
    "#In case we use Google Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5777fc28",
   "metadata": {
    "id": "5777fc28"
   },
   "source": [
    "## Preparing the database (Twitch Corpus)\n",
    "\n",
    "Ideally, a classifier should have data associated with labels. Since machines do not understand words directly, it is best to use numeric labels, such as natural numbers or one-hot encoding. The following code transforms the unique variables contained in the labels column and creates a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9280eba8",
   "metadata": {
    "id": "9280eba8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Upload CSV file\n",
    "df = pd.read_csv('CorpusTwitchVideogames2024FinalV2.csv')\n",
    "\n",
    "# Get the label column\n",
    "labels = df['Emotions']\n",
    "\n",
    "#Label Aprobación is Approval/Empathy/Confidence\n",
    "#Label Desaprobación is Disapproval\n",
    "#Label Decepción/Tristeza is Disappointment/Sadnes\n",
    "#Label Enfado/Ira is Anger\n",
    "#Label Interés/Aceptación/Hype is Interest/Acceptance/Hype\n",
    "#Label Indeterminado is Neutral\n",
    "\n",
    "\n",
    "# Get all unique labels and assign them a numeric value\n",
    "unique_labels = labels.unique()\n",
    "label_to_numeric = {label: i for i, label in enumerate(unique_labels)}\n",
    "\n",
    "# Create a new column with numeric values\n",
    "df['Numeric_Label'] = labels.map(label_to_numeric)\n",
    "\n",
    "# Function to convert numeric label back to text\n",
    "def numeric_to_text(numeric_label):\n",
    "    numeric_to_label = {v: k for k, v in label_to_numeric.items()}\n",
    "    return numeric_to_label[numeric_label]\n",
    "\n",
    "# Example of use of the function\n",
    "print(numeric_to_text(2))  \n",
    "\n",
    "# Save the modified DataFrame in a new CSV file\n",
    "df.to_csv('data_numeric_label_v3.csv', index=False)\n",
    "\n",
    "print(\"A new column with numeric values has been created and the modified DataFrame has been saved in 'data_numeric_label.csv'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0801ca31",
   "metadata": {
    "id": "0801ca31"
   },
   "source": [
    "# Fine-tuning BERT model with clasification layer\n",
    "We load the created database. For this example we used current pytorch, it is suggested to use the version higher than 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8617dc",
   "metadata": {
    "id": "cd8617dc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Step 1: Load data from a CSV file\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    texts = data['Text'].tolist()\n",
    "    labels = data['Numeric_Label'].tolist()\n",
    "    return texts, labels\n",
    "\n",
    "# Path to CSV file\n",
    "file_path = 'data_numeric_label_v3.csv'  # Replace with the path to your CSV file\n",
    "\n",
    "# Load data\n",
    "texts, labels = load_data(file_path)\n",
    "\n",
    "# Step 2: Initialise BERT tokeniser and load pre-trained model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Step 3: Tokenise and encrypt the data\n",
    "encodings = tokenizer(texts, truncation=True, padding=True)\n",
    "\n",
    "# Step 4: Create PyTorch dataset\n",
    "dataset = TensorDataset(torch.tensor(encodings['input_ids']),\n",
    "                        torch.tensor(encodings['attention_mask']),\n",
    "                        torch.tensor(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ecc7ad",
   "metadata": {
    "id": "78ecc7ad"
   },
   "source": [
    "## Model training \n",
    "A model based on \"Bertsequenceclassificator\" is trained to ensure that the pipeline of tokenised data is faster to implement. This model can be fine-tuned using classical methods (hyperparameter settings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6547b9",
   "metadata": {
    "id": "8b6547b9"
   },
   "outputs": [],
   "source": [
    "# Step 5: Configure k-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # We change the K-fold value according to our model\n",
    "\n",
    "# Lists for storing metrics\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "confusion_matrices = []\n",
    "\n",
    "# Step 6: Train and evaluate the model using k-fold cross-validation\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=max(labels)+1).to(device)  \n",
    "# Number of labels is the maximum numeric value in the Numeric_Label column.\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "for fold, (train_indices, test_indices) in enumerate(kf.split(dataset)):\n",
    "    train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "    test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(3):  # 3 training periods in this example (may be modified)\n",
    "        for batch in tqdm(train_loader, desc=\"Fold {} - Época {}\".format(fold+1, epoch + 1)):\n",
    "            optimizer.zero_grad()\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Fold {} - Evaluation\".format(fold+1)):\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = correct / total\n",
    "    accuracies.append(accuracy)\n",
    "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "    precisions.append(precision)\n",
    "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "    recalls.append(recall)\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    print(\"Metrics in the test set (Fold {}):\".format(fold+1))\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1-score:\", f1)\n",
    "\n",
    "    # Calculating and storing the confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    confusion_matrices.append(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461cbda7",
   "metadata": {
    "id": "461cbda7"
   },
   "source": [
    "## Evaluation of the trained BERT model with the classification layer\n",
    "The evaluation is made with the data set not considered during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82f0a8c",
   "metadata": {
    "id": "a82f0a8c"
   },
   "outputs": [],
   "source": [
    "# Calculate and display the average confusion matrix as a heat map with Matplotlib\n",
    "average_cm = np.mean(confusion_matrices, axis=0)\n",
    "\n",
    "# Define label names\n",
    "labels_names = [\"Desaprobación\", \"Aprobación\", \"Decepción\", \"Ira\", \"Indeterminado\", \"Interés\"]\n",
    "\n",
    "#Label Aprobación is Approval/Empathy/Confidence\n",
    "#Label Desaprobación is Disapproval\n",
    "#Label Decepción/Tristeza is Disappointment/Sadnes\n",
    "#Label Enfado/Ira is Anger\n",
    "#Label Interés/Aceptación/Hype is Interest/Acceptance/Hype\n",
    "#Label Indeterminado is Neutral\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(average_cm, interpolation='nearest', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(labels_names))\n",
    "plt.xticks(tick_marks, labels_names, rotation=45)\n",
    "plt.yticks(tick_marks, labels_names)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('Real')\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "# Show the values of the confusion matrix in each cell\n",
    "width, height = average_cm.shape\n",
    "for x in range(width):\n",
    "    for y in range(height):\n",
    "        plt.annotate(str(average_cm[x][y]), xy=(y, x), horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'bert_model_10kfold.pth')\n",
    "\n",
    "# Show average metrics\n",
    "print(\"\\nAverage metrics across all folds:\")\n",
    "print(\"Average accuracy:\", sum(accuracies) / len(accuracies))\n",
    "print(\"Average Precision:\", sum(precisions) / len(precisions))\n",
    "print(\"Average Recall:\", sum(recalls) / len(recalls))\n",
    "print(\"Average F1-score:\", sum(f1_scores) / len(f1_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ba3d4b",
   "metadata": {
    "id": "d8ba3d4b"
   },
   "source": [
    "## Emotional response prediction of the trained BERT model\n",
    "Give a few sentences and test how you classify the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73621154",
   "metadata": {
    "id": "73621154"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Define the device to be used (GPU if available, otherwise CPU).\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pre-trained model\n",
    "model_path = 'bert_model_10kfold.pth' #Here you can load the trained model\n",
    "\n",
    "# Ensure that the number of labels is the same as the number used during training\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6)  \n",
    "\n",
    "#model.load_state_dict(torch.load(model_path))\n",
    "#If no GPU is used add map_location=torch.device('cpu')\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Initialising the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Text classification function\n",
    "def classify_text(text):\n",
    "    # Tokenise and encode text\n",
    "    encoded_text = tokenizer(text, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "    # Passing text through the model\n",
    "    outputs = model(**encoded_text)\n",
    "\n",
    "    # Getting the predictions\n",
    "    _, predicted_class = torch.max(outputs.logits, 1)\n",
    "\n",
    "    return predicted_class.item()\n",
    "\n",
    "# Example of use\n",
    "\n",
    "#Label Aprobación is Approval/Empathy/Confidence\n",
    "#Label Desaprobación is Disapproval\n",
    "#Label Decepción/Tristeza is Disappointment/Sadnes\n",
    "#Label Enfado/Ira is Anger\n",
    "#Label Interés/Aceptación/Hype is Interest/Acceptance/Hype\n",
    "#Label Indeterminado is Neutral\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"Enter a sentence to classify (or 'exit' to exit): \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "    else:\n",
    "        label_id = classify_text(user_input)\n",
    "        labels_names = [\"Aprobación\", \"Decepción\", \"Indeterminado\", \"Interés\", \"Desaprobación\", \"Ira\"]\n",
    "        print(\"The sentence '{}' Has been classified as: {}\".format(user_input, labels_names[label_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ZWumiDUpkNn",
   "metadata": {
    "id": "3ZWumiDUpkNn"
   },
   "source": [
    "## Complete training code in one step\n",
    "All the above steps in one unified notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OfbMRKL1pRih",
   "metadata": {
    "id": "OfbMRKL1pRih"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Step 1: Load data from a CSV file\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    texts = data['Text'].tolist()\n",
    "    labels = data['Numeric_Label'].tolist()\n",
    "    return texts, labels\n",
    "\n",
    "# Path to CSV file\n",
    "file_path = 'data_numeric_label_v3.csv'  # Replace with the path to your CSV file\n",
    "\n",
    "# Load data\n",
    "texts, labels = load_data(file_path)\n",
    "\n",
    "# Step 2: Initialise BERT tokeniser and load pre-trained model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Step 3: Tokenise and encrypt the data\n",
    "encodings = tokenizer(texts, truncation=True, padding=True)\n",
    "\n",
    "# Step 4: Create PyTorch dataset\n",
    "dataset = TensorDataset(torch.tensor(encodings['input_ids']),\n",
    "                        torch.tensor(encodings['attention_mask']),\n",
    "                        torch.tensor(labels))\n",
    "\n",
    "# Step 5: Configure k-fold cross-validation\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=42)  \n",
    "\n",
    "# Lists for storing metrics\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "confusion_matrices = []\n",
    "\n",
    "# Step 6: Train and evaluate the model using k-fold cross-validation\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=max(labels)+1).to(device)  \n",
    "# Number of labels is the maximum numeric value in the Numeric_Label column.\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "for fold, (train_indices, test_indices) in enumerate(kf.split(dataset)):\n",
    "    train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "    test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(8):  # 8 training epoch in this case\n",
    "        for batch in tqdm(train_loader, desc=\"Fold {} - Epoch {}\".format(fold+1, epoch + 1)):\n",
    "            optimizer.zero_grad()\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Fold {} - Evaluation\".format(fold+1)):\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = correct / total\n",
    "    accuracies.append(accuracy)\n",
    "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "    precisions.append(precision)\n",
    "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "    recalls.append(recall)\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    print(\"Metrics in the test set (Fold {}):\".format(fold+1))\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1-score:\", f1)\n",
    "\n",
    "    # Calculate and store the confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    confusion_matrices.append(cm)\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), 'bert_model_V6_fold_{}.pth'.format(fold+1))\n",
    "\n",
    "# Calculate and display the average confusion matrix as a heat map with Matplotlib\n",
    "average_cm = np.mean(confusion_matrices, axis=0)\n",
    "average_cm = np.round(average_cm).astype(int)\n",
    "\n",
    "# Define label names\n",
    "labels_names = [\"Desaprobación\", \"Aprobación\", \"Decepción\", \"Ira\", \"Indeterminado\", \"Interés\"]\n",
    "#Label Aprobación is Approval/Empathy/Confidence\n",
    "#Label Desaprobación is Disapproval\n",
    "#Label Decepción/Tristeza is Disappointment/Sadnes\n",
    "#Label Enfado/Ira is Anger\n",
    "#Label Interés/Aceptación/Hype is Interest/Acceptance/Hype\n",
    "#Label Indeterminado is Neutral\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(average_cm, interpolation='nearest', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(labels_names))\n",
    "plt.xticks(tick_marks, labels_names, rotation=45)\n",
    "plt.yticks(tick_marks, labels_names)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('Real')\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "# Display confusion matrix values in each cell\n",
    "width, height = average_cm.shape\n",
    "for x in range(width):\n",
    "    for y in range(height):\n",
    "        plt.annotate(str(average_cm[x][y]), xy=(y, x), horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Display average metrics\n",
    "print(\"\\nAverage metrics across all folds:\")\n",
    "print(\"Average accuracy:\", sum(accuracies) / len(accuracies))\n",
    "print(\"Average Precision:\", sum(precisions) / len(precisions))\n",
    "print(\"Average Recall:\", sum(recalls) / len(recalls))\n",
    "print(\"Average F1-score:\", sum(f1_scores) / len(f1_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZdVHB5ZtZ0li",
   "metadata": {
    "id": "ZdVHB5ZtZ0li"
   },
   "source": [
    "# Obtaining trained model metrics, both globally and by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z5gKPzy-Z1Wa",
   "metadata": {
    "id": "z5gKPzy-Z1Wa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define the device to be used (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load tokeniser\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Load the pre-trained model\n",
    "model_path = 'bert_model_V6_fold_7.pth'\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Loading the database from a CSV file\n",
    "data = pd.read_csv(\"data_numeric_label_v3.csv\")  # Replace with the actual path of your CSV file\n",
    "\n",
    "# Split data into features (X) and labels (y)\n",
    "X = data['Text']  # Assuming you have a column called \"Text\" that contains your data\n",
    "y = data['Numeric_Label']  # Assuming you have a column called \"Numeric_Label\" that contains the labels\n",
    "\n",
    "# Prepare inputs and labels as tensioners\n",
    "inputs = tokenizer(list(X), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "labels = torch.tensor(y.values)\n",
    "\n",
    "# Create a DataLoader to iterate over data with a progress bar\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n",
    "dataloader = DataLoader(dataset, batch_size=8)\n",
    "\n",
    "# Initialising metrics\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Making inference with the progress bar\n",
    "for batch in tqdm(dataloader, desc=\"Inference\"):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    inputs = {'input_ids': batch[0], 'attention_mask': batch[1]}\n",
    "    labels = batch[2]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    true_labels.extend(labels.cpu().numpy())\n",
    "    predicted_labels.extend(torch.argmax(outputs.logits, dim=1).cpu().numpy())\n",
    "\n",
    "# Calculatinog metrics\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "report = classification_report(true_labels, predicted_labels, target_names=[\"Aprobación\", \"Decepción\", \"Indeterminado\", \"Interés\", \"Desaprobación\", \"Ira\"])\n",
    "\n",
    "# Calculate the confusion matrix by class\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate accuracy, recall and F1-score for each class\n",
    "class_metrics = classification_report(true_labels, predicted_labels, target_names=[\"Aprobación\", \"Decepción\", \"Indeterminado\", \"Interés\", \"Desaprobación\", \"Ira\"], output_dict=True)\n",
    "\n",
    "# Print results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification report:\")\n",
    "print(report)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Class metrics:\")\n",
    "for clase, metrics in class_metrics.items():\n",
    "    if clase != 'Accuracy':  # Exclude the global accuracy metric\n",
    "        print(f\"Clase {clase}:\")\n",
    "        print(f\"  Precisión: {metrics['precision']}\")\n",
    "        print(f\"  Recall: {metrics['recall']}\")\n",
    "        print(f\"  F1-score: {metrics['f1-score']}\")\n",
    "\n",
    "# Visualising the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Aprobación\", \"Decepción\", \"Indeterminado\", \"Interés\", \"Desaprobación\", \"Ira\"], yticklabels=[\"Aprobación\", \"Decepción\", \"Indeterminado\", \"Interés\", \"Desaprobación\", \"Ira\"])\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"Real labels\")\n",
    "plt.title(\"Visulisation of the Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "#Label Aprobación is Approval/Empathy/Confidence\n",
    "#Label Desaprobación is Disapproval\n",
    "#Label Decepción/Tristeza is Disappointment/Sadnes\n",
    "#Label Enfado/Ira is Anger\n",
    "#Label Interés/Aceptación/Hype is Interest/Acceptance/Hype\n",
    "#Label Indeterminado is Neutral\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e32a120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define the device to be used (GPU if available, otherwise CPU).\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load tokeniser\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Load the pre-trained model\n",
    "model_path = '/content/drive/MyDrive/BERTAttentMask_SM/bert_model_V8_fold_8.pth'\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Loading the database from a CSV file\n",
    "data = pd.read_csv(\"/content/drive/MyDrive/BERTAttentMask_SM/data_numeric_label_v3.csv\")  \n",
    "\n",
    "# Split data into features (X) and labels (y)\n",
    "X = data['Text']  # Assuming you have a column called \"Text\" that contains your data\n",
    "y = data['Numeric_Label']  # Assuming you have a column called \"Numeric_Label\" that contains the labels\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# prepare inputs and labels as tensioners\n",
    "train_inputs = tokenizer(list(X_train), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "train_labels = torch.tensor(y_train.values)\n",
    "test_inputs = tokenizer(list(X_test), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "test_labels = torch.tensor(y_test.values)\n",
    "\n",
    "# Create DataLoaders to iterate over data with a progress bar\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(train_inputs['input_ids'], train_inputs['attention_mask'], train_labels)\n",
    "test_dataset = TensorDataset(test_inputs['input_ids'], test_inputs['attention_mask'], test_labels)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "# Initialising metrics\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Performing inference with the test set\n",
    "for batch in tqdm(test_dataloader, desc=\"Inference on test set\"):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    inputs = {'input_ids': batch[0], 'attention_mask': batch[1]}\n",
    "    labels = batch[2]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    true_labels.extend(labels.cpu().numpy())\n",
    "    predicted_labels.extend(torch.argmax(outputs.logits, dim=1).cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "report = classification_report(true_labels, predicted_labels, target_names=[\"Aprobación\", \"Decepción\", \"Indeterminado\", \"Interés\", \"Desaprobación\", \"Ira\"])\n",
    "\n",
    "# Calculate the confusion matrix by class\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate accuracy, recall and F1-score for each class\n",
    "class_metrics = classification_report(true_labels, predicted_labels, target_names=[\"Aprobación\", \"Decepción\", \"Indeterminado\", \"Interés\", \"Desaprobación\", \"Ira\"], output_dict=True)\n",
    "\n",
    "# Print results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification report:\")\n",
    "print(report)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Class metrics:\")\n",
    "for clase, metrics in class_metrics.items():\n",
    "    if clase != 'Accuracy':  # Exclude the global accuracy metric\n",
    "        print(f\"Clase {clase}:\")\n",
    "        print(f\"  Precisión: {metrics['precision']}\")\n",
    "        print(f\"  Recall: {metrics['recall']}\")\n",
    "        print(f\"  F1-score: {metrics['f1-score']}\")\n",
    "\n",
    "# Visualising the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Aprobación\", \"Decepción\", \"Indeterminado\", \"Interés\", \"Desaprobación\", \"Ira\"], yticklabels=[\"Aprobación\", \"Decepción\", \"Indeterminado\", \"Interés\", \"Desaprobación\", \"Ira\"])\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"Real labels\")\n",
    "plt.title(\"Visulisation of the Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "#Label Aprobación is Approval/Empathy/Confidence\n",
    "#Label Desaprobación is Disapproval\n",
    "#Label Decepción/Tristeza is Disappointment/Sadnes\n",
    "#Label Enfado/Ira is Anger\n",
    "#Label Interés/Aceptación/Hype is Interest/Acceptance/Hype\n",
    "#Label Indeterminado is Neutral"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
